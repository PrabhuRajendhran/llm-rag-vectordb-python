{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331d43e6-031d-4dc3-ba24-eeb453a14055",
   "metadata": {},
   "source": [
    "# Gettings started with Amazon `Bedrock`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d55a7d-204a-4738-904a-2da5a695fb82",
   "metadata": {},
   "source": [
    "![](images/bedrock_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab536f45-a505-4341-83d4-a2cf64039b88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create a `bedrock` client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc42da1-a040-4de2-bf1e-ed08ef3ad5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "#Create the connection to Bedrock\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    region_name='us-west-2', \n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2', \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b918e6-78a1-4426-813a-0608892089bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### List of all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d421313-4275-4ab2-824c-ebd543345574",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon.titan-tg1-large',\n",
       " 'amazon.titan-embed-g1-text-02',\n",
       " 'amazon.titan-text-lite-v1:0:4k',\n",
       " 'amazon.titan-text-lite-v1',\n",
       " 'amazon.titan-text-express-v1:0:8k',\n",
       " 'amazon.titan-text-express-v1',\n",
       " 'amazon.titan-embed-text-v1:2:8k',\n",
       " 'amazon.titan-embed-text-v1',\n",
       " 'amazon.titan-embed-image-v1:0',\n",
       " 'amazon.titan-embed-image-v1',\n",
       " 'amazon.titan-image-generator-v1:0',\n",
       " 'amazon.titan-image-generator-v1',\n",
       " 'stability.stable-diffusion-xl',\n",
       " 'stability.stable-diffusion-xl-v0',\n",
       " 'stability.stable-diffusion-xl-v1:0',\n",
       " 'stability.stable-diffusion-xl-v1',\n",
       " 'ai21.j2-grande-instruct',\n",
       " 'ai21.j2-jumbo-instruct',\n",
       " 'ai21.j2-mid',\n",
       " 'ai21.j2-mid-v1',\n",
       " 'ai21.j2-ultra',\n",
       " 'ai21.j2-ultra-v1',\n",
       " 'anthropic.claude-instant-v1:2:100k',\n",
       " 'anthropic.claude-instant-v1',\n",
       " 'anthropic.claude-v2:0:18k',\n",
       " 'anthropic.claude-v2:0:100k',\n",
       " 'anthropic.claude-v2:1:18k',\n",
       " 'anthropic.claude-v2:1:200k',\n",
       " 'anthropic.claude-v2:1',\n",
       " 'anthropic.claude-v2',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
       " 'cohere.command-text-v14:7:4k',\n",
       " 'cohere.command-text-v14',\n",
       " 'cohere.command-light-text-v14:7:4k',\n",
       " 'cohere.command-light-text-v14',\n",
       " 'cohere.embed-english-v3',\n",
       " 'cohere.embed-multilingual-v3',\n",
       " 'meta.llama2-13b-chat-v1:0:4k',\n",
       " 'meta.llama2-13b-chat-v1',\n",
       " 'meta.llama2-70b-chat-v1:0:4k',\n",
       " 'meta.llama2-70b-chat-v1',\n",
       " 'meta.llama2-13b-v1:0:4k',\n",
       " 'meta.llama2-13b-v1',\n",
       " 'meta.llama2-70b-v1:0:4k',\n",
       " 'meta.llama2-70b-v1',\n",
       " 'mistral.mistral-7b-instruct-v0:2',\n",
       " 'mistral.mixtral-8x7b-instruct-v0:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all foundation models\n",
    "all_llms = [ model['modelId'] for model in bedrock.list_foundation_models()['modelSummaries']]\n",
    "all_llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624768d-a79c-417e-aec5-272e95df6bf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Define prompt and model parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424ed56-7725-4b51-b027-ee53b2de1b48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Amazon Titan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a9ba82-62d6-49bd-ac1e-967d5bc59d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"Write me a poem about apples\"\"\"\n",
    "\n",
    "text_gen_config = {\n",
    "                    \"maxTokenCount\": 512,\n",
    "                    \"stopSequences\": [], \n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "\n",
    "body = json.dumps({\n",
    "                        \"inputText\": prompt_data,\n",
    "                        \"textGenerationConfig\": text_gen_config  \n",
    "                    })\n",
    "\n",
    "model_id = 'amazon.titan-tg1-large'\n",
    "accept = 'application/json' \n",
    "content_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc650c9-a75c-4ed4-ae0a-e3e0a5e38914",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3702c51b-a622-4635-aeb7-e3309013ef29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "                                            body=body, \n",
    "                                            modelId=model_id, \n",
    "                                            accept=accept, \n",
    "                                            contentType=content_type\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e7285-e061-4886-934f-904da5d43fa7",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06be453a-62d5-400e-aca1-f3b1beb0dd1e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a poem about apples:\n",
      "\n",
      "Apples are so round and bright,\n",
      "They make my mouth water with delight.\n",
      "Their skin is so smooth and crisp,\n",
      "I can't help but eat them every day.\n",
      "\n",
      "They come in red, yellow, and green,\n",
      "But my favorite is the pink and serene.\n",
      "I eat them with peanut butter,\n",
      "They're the perfect snack for any time.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac6718-0a38-40c1-a31d-0bc6d8301e22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Anthropic (Claude v3 (Sonnet))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d357de4b-8c0d-4317-b14e-b099adbe722c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"What Large in LLM means\"\"\"\n",
    "\n",
    "body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1024,\n",
    "            \"messages\": [\n",
    "                 {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_data\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "body = json.dumps(body) # Encode body as JSON string\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8cb2f-0478-4697-86d0-590fbf8be22d",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c204dee-e262-4c40-becf-8af9255f6145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de6d86-bff5-4a73-a2ff-c7ec38c49d81",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe2e98a-515f-4896-89fe-d96f1e4b00c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of LLMs (Large Language Models), the term \"Large\" refers to the massive size and complexity of these models in terms of the number of parameters they contain.\n",
      "\n",
      "LLMs are deep learning models trained on vast amounts of text data to acquire broad knowledge and capabilities in natural language processing tasks. They have achieved remarkable performance by scaling up the model size, measured by the number of parameters (weights and biases) they possess.\n",
      "\n",
      "Some key points about the \"Large\" in LLMs:\n",
      "\n",
      "1. Parameter Count: LLMs typically have hundreds of billions or even trillions of parameters. For example, GPT-3 (one of the most well-known LLMs) has 175 billion parameters, while the more recent PaLM model has 540 billion parameters.\n",
      "\n",
      "2. Model Capacity: The large number of parameters allows LLMs to capture and model intricate patterns and relationships in the training data, enabling them to handle complex natural language tasks with high accuracy and fluency.\n",
      "\n",
      "3. Training Data: To train such massive models effectively, LLMs require enormous amounts of text data from diverse sources, such as books, websites, and databases, often amounting to terabytes or petabytes of data.\n",
      "\n",
      "4. Computational Resources: Training and deploying LLMs demand significant computational resources, including high-performance GPUs or TPUs, distributed training infrastructure, and substantial memory capacity.\n",
      "\n",
      "5. Capabilities: The \"Large\" scale of LLMs allows them to perform well on a wide range of natural language tasks, including text generation, question answering, summarization, translation, and more, often achieving human-level or even superhuman performance in certain benchmarks.\n",
      "\n",
      "However, it's important to note that model size alone does not guarantee superior performance, and other factors like architecture, training data quality, and optimization techniques also play crucial roles in the effectiveness of LLMs.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get(\"body\").read())\n",
    "for output in response_body.get(\"content\", []):\n",
    "    print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f983c62-5db4-4939-99cd-01ed5cf50ece",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Mistral (mixtral-8x7b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc9fd10c-b83f-45c4-9e1a-9b55e1736354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"<s>[INST]Craft a Python function to convert Celsius to Fahrenheit. If water boils at 100°C, what's that in Fahrenheit?[/INST]\"\"\"\n",
    "\n",
    "body = json.dumps({ \n",
    "    'prompt': prompt_data,\n",
    "    'max_tokens': 200,\n",
    "    'top_p': 0.9,\n",
    "    'temperature': 0.2,\n",
    "})\n",
    "\n",
    "\n",
    "modelId = 'mistral.mixtral-8x7b-instruct-v0:1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83e979-9d72-4ab7-9acb-3afc89687213",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a285cc8b-b9df-4339-8b69-8e9594a8e9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                        modelId=modelId, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15918b5d-1068-4d93-9309-c1d3f2e903b6",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e49eef-0d1b-43c2-a6a6-5a8aca398db0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a simple Python function to convert Celsius to Fahrenheit:\n",
      "\n",
      "```python\n",
      "def celsius_to_fahrenheit(celsius):\n",
      "    return (celsius * 9/5) + 32\n",
      "```\n",
      "\n",
      "Now, let's use this function to convert 100 degrees Celsius to Fahrenheit:\n",
      "\n",
      "```python\n",
      "print(celsius_to_fahrenheit(100))\n",
      "```\n",
      "\n",
      "When you run this code, it will output `212.0`, which is the boiling point of water in Fahrenheit.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('outputs')[0].get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656ce38-e3dd-492f-b035-8a708cbe34b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Syntax Multi-Modal models from `Anthropic Claude v3 Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79dcda90-954d-4c0c-92a2-cb2479f0adb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"images/cat.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"body\": {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": base64_string\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Write me a detailed description of this photo.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the payload to bytes\n",
    "body_bytes = json.dumps(payload['body']).encode('utf-8')\n",
    "\n",
    "# Invoke the model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body_bytes,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3482f6-bfa5-4006-867e-e5a35a089e8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a cute, cartoon-style illustration of a tabby cat. The cat has large, expressive eyes with brown irises that give it an adorable and endearing look. Its face features a small pink nose, white whiskers, and a smiling expression, revealing its front teeth.\n",
      "\n",
      "The cat's body is orange and white in color, with distinct striped markings reminiscent of a tabby cat breed. Its front paws are white, while the rest of its legs and tail are striped orange and white. The tail curves elegantly behind the cat's body.\n",
      "\n",
      "The illustration has a simplistic yet charming style, with a gray background that allows the vibrant colors of the cat to stand out. The overall image conveys a sense of playfulness and warmth, capturing the endearing nature of a beloved feline companion.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('content')[0].get('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f57584-eca6-4602-a6a6-ab39528d13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
