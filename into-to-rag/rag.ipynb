{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG application from scratch\n",
    "\n",
    "Here is a high-level overview of the system we want to build:\n",
    "\n",
    "<img src='./images/system1.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the environment variables we need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# This is the YouTube video [Jeff Bezos and Lex Fridman]\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=lB_0hR5s41Y&ab_channel=BeerBiceps\"\n",
    "S3_BUCKET = 'ml-dl-demo-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "Let's define the LLM model that we'll use as part of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = BedrockChat(model_id=\"anthropic.claude-v2\", model_kwargs={\"temperature\": 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model by asking a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"England won the ICC Cricket World Cup 2019 by defeating New Zealand in a thrilling final at Lord's in London. The scores were tied after both teams scored 241 runs in their 50 overs, and the match went to a Super Over where the scores were again tied. England won based on boundary count.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Who won the ICC Criket World Cup 2019?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from the model is an `AIMessage` instance containing the answer. We can extract this answer by chaining the model with an [output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/).\n",
    "\n",
    "Here is what chaining the model with an output parser looks like:\n",
    "\n",
    "<img src='./images/chain1.png' width=\"1200\">\n",
    "\n",
    "For this example, we'll use a simple `StrOutputParser` to extract the answer as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"England won the ICC Cricket World Cup 2019 by defeating New Zealand in a thrilling final at Lord's in London. The scores were tied after both teams scored 241 runs in their 50 overs, and the match went to a Super Over where the scores were again tied. England won based on boundary count, as they had hit more boundaries (26 to New Zealand's 17) in the match. It was the first time a World Cup final was decided on boundary count. Overall, it was an incredible match that came down to the finest of margins.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"Who won the ICC Criket World Cup 2019?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing prompt templates\n",
    "\n",
    "We want to provide the model with some context and the question. [Prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/quick_start) are a simple way to define and reuse prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now chain the prompt with the model and the output parser.\n",
    "\n",
    "<img src='./images/chain2.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Susana'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\": \"Mary's sister is Susana\",\n",
    "    \"question\": \"Who is Mary's sister?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining chains\n",
    "\n",
    "We can combine different chains to create more complex workflows. For example, let's create a second chain that translates the answer from the first chain into a different language.\n",
    "\n",
    "Let's start by creating a new prompt template for the translation chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "                                                        \"Translate {answer} to {language}\"\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new translation chain that combines the result from the first chain with the translation prompt.\n",
    "\n",
    "Here is what the new workflow looks like:\n",
    "\n",
    "<img src='./images/chain3.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'दिए गए संदर्भ के आधार पर, मैरी की एक बहन सुसाना है और उसके और कोई भाई-बहन नहीं हैं। इसलिए, उत्तर यह है कि मैरी की एक बहन है।'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain = (\n",
    "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
    ")\n",
    "\n",
    "translation_chain.invoke(\n",
    "    {\n",
    "        \"context\": \"Mary's sister is Susana. She doesn't have any more siblings.\",\n",
    "        \"question\": \"How many sisters does Mary have?\",\n",
    "        \"language\": \"Hindi\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing the YouTube Video\n",
    "\n",
    "The context we want to send the model comes from a YouTube video. Let's download the video and transcribe it using [OpenAI's Whisper](https://openai.com/research/whisper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription file already exists.\n"
     ]
    }
   ],
   "source": [
    "from utils import transcribe_video\n",
    "\n",
    "transcribe_video(s3_bucket_name=S3_BUCKET, youtube_video_url=YOUTUBE_VIDEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the transcription and display the first few characters to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're a multibillionaire European founder who's moved to Gandhinagar. Yes. Why did you choose Gujar\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"transcription.txt\", \"r\") as file:\n",
    "    transcription = json.loads(file.read())\n",
    "    transcription = transcription['results']['transcripts'][0]['transcript']\n",
    "\n",
    "transcription[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the entire transcription as context\n",
    "\n",
    "If we try to invoke the chain using the transcription as context, the model will return an error because the context is too long.\n",
    "\n",
    "Large Language Models support limitted context sizes. The video we are using is too long for the model to handle, so we need to find a different solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114926"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7 s ± 521 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "chain.invoke({\"context\": transcription,\n",
    "              \"question\": \"What matters when selecting a location for a business in India ?\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the transcription\n",
    "\n",
    "Since we can't use the entire transcription as the context for the model, a potential solution is to split the transcription into smaller chunks. We can then invoke the model using only the relevant chunks to answer a particular question:\n",
    "\n",
    "<img src='./images/system2.png' width=\"1200\">\n",
    "\n",
    "Let's start by loading the transcription in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "text_documents = loader.load()\n",
    "\n",
    "# text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to split a document. For this example, we'll use a simple splitter that splits the document into chunks of a fixed size. Check [Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/) for more information about different approaches to splitting documents.\n",
    "\n",
    "For illustration purposes, let's split the transcription into chunks of 100 characters with an overlap of 20 characters and display the first few chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='{\"jobName\":\"Multi-BillionairesJourneyInIndia-LeadershipCultureAndOpportunityOdooTRS386.mp41711386077', metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content='TRS386.mp41711386077\",\"accountId\":\"507922848584\",\"status\":\"COMPLETED\",\"results\":{\"transcripts\":[{\"tr', metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content='{\"transcripts\":[{\"transcript\":\"You\\'re', metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"a multibillionaire European founder who's moved to Gandhinagar. Yes. Why did you choose Gujarat? In\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content='choose Gujarat? In India? We have a ruler to do is we never go to tier one cities. We always go to', metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text_splitter.split_documents(text_documents)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our specific application, let's use 1000 characters instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the relevant chunks\n",
    "\n",
    "Given a particular question, we need to find the relevant chunks from the transcription to send to the model. Here is where the idea of **embeddings** comes into play.\n",
    "\n",
    "An embedding is a mathematical representation of the semantic meaning of a word, sentence, or document. It's a projection of a concept in a high-dimensional space. Embeddings have a simple characteristic: The projection of related concepts will be close to each other, while concepts with different meanings will lie far away. You can use the [Cohere's Embed Playground](https://dashboard.cohere.com/playground/embed) to visualize embeddings in two dimensions.\n",
    "\n",
    "To provide with the most relevant chunks, we can use the embeddings of the question and the chunks of the transcription to compute the similarity between them. We can then select the chunks with the highest similarity to the question and use them as the context for the model:\n",
    "\n",
    "<img src='./images/system3.png' width=\"1200\">\n",
    "\n",
    "Let's generate embeddings for an arbitrary query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 1536\n",
      "[1.2890625, 0.4453125, 0.28320312, 0.3984375, 0.050048828, -0.123046875, 0.58984375, -0.0007247925, -0.23535156, 0.48046875]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "embeddings = BedrockEmbeddings()\n",
    "embedded_query = embeddings.embed_query(\"Berlin is in Germany\")\n",
    "\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how embeddings work, let's first generate the embeddings for two different sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = embeddings.embed_query(\"Welcome to Frankfurt\")\n",
    "sentence2 = embeddings.embed_query(\"This is a table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the similarity between the query and each of the two sentences. The closer the embeddings are, the more similar the sentences will be.\n",
    "\n",
    "We can use [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) to calculate the similarity between the query and each of the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6138958023127881, 0.2699050016319834)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "query_sentence1_similarity, query_sentence2_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Vector Store\n",
    "\n",
    "We need an efficient way to store document chunks, their embeddings, and perform similarity searches at scale. To do this, we'll use a **vector store**.\n",
    "\n",
    "A vector store is a database of embeddings that specializes in fast similarity searches. \n",
    "\n",
    "<img src='./images/system4.png' width=\"1200\">\n",
    "\n",
    "To understand how a vector store works, let's create one in memory and add a few embeddings to it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing vectors in Amazon Aurora using `pgvector`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; padding: 10px; border-radius: 5px; font-size: 1.1em;\">\n",
    "<b>Prerequisite:</b>\n",
    "<ol>\n",
    "    <li>Have an <b>Aurora cluster ready</b>.</li>\n",
    "    <li>Create the <b>pgvector extension</b> on your Aurora PostgreSQL database (DB) cluster:\n",
    "        <pre style=\"font-size: 1.1em;\"><code>\n",
    "        CREATE EXTENSION vector;\n",
    "        </code></pre>\n",
    "    </li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can connect to the Aurora cluster and check \n",
    "\n",
    "\n",
    "```sql\n",
    "-- SHOW the current database\n",
    "SELECT current_database();\n",
    "\n",
    "-- SHOW all the tables in the database\n",
    "SELECT table_name\n",
    "FROM postgres.information_schema.tables\n",
    "WHERE table_schema = 'public';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector, DistanceStrategy\n",
    "\n",
    "# Loading all env variables \n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = 'rag-intro-on-aws'\n",
    "\n",
    "# Connection String\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(driver = os.getenv(\"PGVECTOR_DRIVER\"),\n",
    "                                                              user = os.getenv(\"PGVECTOR_USER\"),                                      \n",
    "                                                              password = os.getenv(\"PGVECTOR_PASSWORD\"),                                  \n",
    "                                                              host = os.getenv(\"PGVECTOR_HOST\"),                                            \n",
    "                                                              port = os.getenv(\"PGVECTOR_PORT\"),                                          \n",
    "                                                              database = os.getenv(\"PGVECTOR_DATABASE\"),\n",
    "                                                              )  \n",
    "\n",
    "# Text Embedding model\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "# Creating the VectorDB store instance   \n",
    "vectorstore1 = PGVector(collection_name=COLLECTION_NAME,\n",
    "                           connection_string=CONNECTION_STRING,\n",
    "                           embedding_function=embeddings,\n",
    "                           distance_strategy = DistanceStrategy.EUCLIDEAN,\n",
    "                           use_jsonb = True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c6de01da-ead0-11ee-ae82-3eaa6d286609',\n",
       " 'c6de0428-ead0-11ee-ae82-3eaa6d286609',\n",
       " 'c6de0496-ead0-11ee-ae82-3eaa6d286609',\n",
       " 'c6de04e6-ead0-11ee-ae82-3eaa6d286609',\n",
       " 'c6de052c-ead0-11ee-ae82-3eaa6d286609',\n",
       " 'c6de0572-ead0-11ee-ae82-3eaa6d286609',\n",
       " 'c6de05ae-ead0-11ee-ae82-3eaa6d286609']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.add_texts([\n",
    "                    \"Color of the bird is red\"\n",
    "                    \"The cat slept by the fire.\",\n",
    "                    \"We went to the park after school.\",\n",
    "                    \"I finished my homework early.\",\n",
    "                    \"The bird sang a beautiful song.\",\n",
    "                    \"She read a book before bed.\",\n",
    "                    \"Mary has two siblings\",\n",
    "                    \"Song was in Spanish\", \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the vector store to find the most similar embeddings to a given query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='The bird sang a beautiful song.'),\n",
       "  12.719913663751074),\n",
       " (Document(page_content='The bird sang a beautiful song.'),\n",
       "  12.719913663751074),\n",
       " (Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       "  18.77422507321166)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.similarity_search_with_score(query=\"What the bird was singing\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the vector store to the chain\n",
    "\n",
    "We can use the vector store to find the most relevant chunks from the transcription to send to the model. Here is how we can connect the vector store to the chain:\n",
    "\n",
    "<img src='./images/chain4.png' width=\"1200\">\n",
    "\n",
    "We need to configure a [Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/). The retriever will run a similarity search in the vector store and return the most similar documents back to the next step in the chain.\n",
    "\n",
    "We can get a retriever directly from the vector store we created before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       " Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       " Document(page_content='The bird sang a beautiful song.'),\n",
       " Document(page_content='The bird sang a beautiful song.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever1 = vectorstore1.as_retriever()\n",
    "retriever1.invoke(\"Whats the color of the bird who was singing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prompt expects two parameters, \"context\" and \"question.\" We can use the retriever to find the chunks we'll use as the context to answer the question.\n",
    "\n",
    "We can create a map with the two inputs by using the [`RunnableParallel`](https://python.langchain.com/docs/expression_language/how_to/map) and [`RunnablePassthrough`](https://python.langchain.com/docs/expression_language/how_to/passthrough) classes. This will allow us to pass the context and question to the prompt as a map with the keys \"context\" and \"question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       "  Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       "  Document(page_content='The bird sang a beautiful song.'),\n",
       "  Document(page_content='The bird sang a beautiful song.')],\n",
       " 'question': 'Whats the color of the bird who was singing?'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
    "setup.invoke(\"Whats the color of the bird who was singing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add the setup map to the chain and run it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, I don\\'t have enough information to determine the color of the bird who was singing. The context mentions a red bird, but does not specify if this red bird is the one singing. Since I cannot definitively answer the question, I must reply \"I don\\'t know\".'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | parser\n",
    "chain.invoke(\"Whats the color of the bird who was singing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's invoke the chain using another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, I can infer that Mary has two siblings. Since siblings refers to brothers and/or sisters, Mary must have at least one brother or sister. Therefore, the answer is yes, Mary has a brother or sister.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Does Mary has any brother or sister ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading transcription into the vector store\n",
    "\n",
    "We initialized the vector store with a few random strings. Let's create a new vector store using the chunks from the video transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Aurora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading all env variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load the text from the file\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "# Set the collection name\n",
    "COLLECTION_NAME = \"rag-intro-yt\"\n",
    "\n",
    "# Connection String\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.getenv(\"PGVECTOR_DRIVER\"),\n",
    "    user=os.getenv(\"PGVECTOR_USER\"),\n",
    "    password=os.getenv(\"PGVECTOR_PASSWORD\"),\n",
    "    host=os.getenv(\"PGVECTOR_HOST\"),\n",
    "    port=os.getenv(\"PGVECTOR_PORT\"),\n",
    "    database=os.getenv(\"PGVECTOR_DATABASE\"),\n",
    ")\n",
    "\n",
    "# Create the PGVector instance from the documents\n",
    "db = PGVector.from_documents(\n",
    "                                embedding=embeddings,\n",
    "                                documents=docs,\n",
    "                                collection_name=COLLECTION_NAME,\n",
    "                                connection_string=CONNECTION_STRING,\n",
    "                                use_jsonb = True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run a similarity search on pinecone to make sure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"that. You like how you're working, right? The reason is that um uh public companies tend to refocus on the short term, you know, you have to uh publish earning codes with the, the sales number and if the numbers are good, everyone is happy, they buy the shares. If numbers are bad, people are not happy and your employees are frustrated because they have shares and it's bad. So public companies have a tendency to focus on the short term to saves, saves of the moments of the quarter and so on. I don't want that the success of FU is always to build for the long term. And I don't want to see on to look for the short term or the sales number of the quarter. One, the other thing is I'm so much focused on productivity and efficiency. Uh When you get public, you need extra layers of reporting transparency, uh anything like that. Uh So second reason I don't want that I want to be super efficient, decide right away instead of asking the board of directors. Um And third, I like open and transparent communication. You know, I just said the company was 4.5 billion of euro. If I was a public company, I could go to jail because I disclosed information uh not be before the earning calls. I think if, if I would have sent that to maybe not publicly but to some I could go to jail. I don't want that. I want to be able to say whatever I want to inform my employees uh and be transparent. Why do you think founders choose to go public? I think a lot of them don't understand, it's just a way to get cash. Um But to understand the consequence of that, most of them don't catch it really another thing. It's bad. I think as a source of cash public is quite good, it's efficient but it comes with some drawbacks like you have to uh have extra layers of reporting complexity. You cannot disclose information and it will refocus the mindset to the short term for some companies. It's good. Some companies need to focus on the short term but it's not us. You know, I would go as far as saying and I might be totally wrong while saying this, but I think there's a bit of a glamour factor also. Yeah, it's a way of being recognized but it's very short term. Like the moment you get public, everyone praise you, you get a lot of praise and then it goes back to reality after deal with the devil. Yeah, you get the same articles that we publish the de because it not big deal. But, um, I'm extreme in everything I do for me. If I lose 1% of productivity, it's bad. I wouldn't want that for do. Um, but, but it's not the devil. It's a, what's the best career advice you ever got in your life from someone? Just do it. That's true because a lot of people a re thinking waiting for the good idea. Um, deciding how we should do it sometime it's just about move on, get the job done first, get the job and maybe it works. Maybe it won't work. But at least you move forward and what's the worst advice you have about advice? I don't know. Um, open uh uh, no, I didn't get bad advice. I didn't follow advice. I don't have mentors and everything. I was working in the other office, which is a farm, in a farm, quite alone, not meeting a lot of people. So I didn't get a lot of feedback. I'm gonna give you a compliment again. Same compliment. You're a crazy guy. Like I have not met anyone like you on the show. No, I think a lot of people who bootstrap do that. You start from where you are and your small things and I don't just mean your professional and even the guy you are, it's very different man. Like, you know, I, I have not seen this on the show and I've spoken to like 600 people, like I've not met someone who's done so much materially, but it's still so humble. Like I still feel you're like a code on the inside. You know, you, that's what I love. I am. A but then that affects a lot of how you look at life. Like someone, not someone else. Many other people in your position would have accomplished what you've accomplished at this point. Either would have chosen to sell it off and just relax or, you know, live more. But then will they be happy by doing that? I think different people have different life stories for me. There is nothing better that I can do than to do. The best I can do is to continue improving the software for companies. It's, I feel like I don't see what I can do better than that, I mean, are you changing as a person as you age? Not as a professional as a human being. Are you changing? I become better. No, I think, no, I become slower because of the age. Um But I think the vision and uh what I wanted to do has always been the same uh not at the very beginning but after a few years it, it has been there. How do you look at Silicon Valley and San Francisco generally? Is it, is it always going to be the center of tech in the world or? Yes, they have a big advance. Um For not for the reason we think the main reason is the cash. They have so many V CS or old ex Google employs with plenty of millions to invest that basically any ID can, can live there and when, when all the ID can leave, some of them will be good and will make a good company. Do you visit? I have an office in San Francisco. Yes. And before office was in uh uh in Silicon Valley and I lived three years there. You lived three years with the family? Yes. Can you talk to me more right now? You're OK to talk to me. Are you getting bored? No, you're enjoying this. I just want to stretch the conversation more. I want to get to know more. Let's go. You don't mind me asking all these questions, right? Like all this time How are you feeling, by the way, in this? Iiiii, I enjoy the, the, the, it's good. We have a good conversation and it's fun because you're getting to think. Uh, yes. And for me it's a different thing that what I used to do. So it's good. Ok. Um, usually people like yourself who come on the show, it's a thought exercise for them because the questions go, like, pretty intense. So, especially entrepreneurs enjoyed being on the show because they get to think much more. They get to reflect. I don't know if you're in that zone. I don't need to think that much because I know my subject. So these things I'm used to talk about. So what value is this conversation adding to you? Not, not, not just you, I'm surprised that you find that the discussion is so good for you that you get a lot of value from it for me just no matter. Ok, but you are adding a lot of value. Like that's why I'm surprised. And it's good to hear. I'm sure this one is going to get international viewers as well because you've not just spoken to the Indian audiences. You know, you've spoken to like, like a lot of people want to expand the businesses in India and they don't know how to my solution to all of them. And I've been asked this question abroad is I think you need to tie up with an Indian partner. Like Indians have the team mentality also like as we value to find. Uh So, I mean, that was my advice until today's podcast. Now, I'll just send them this podcast. Look at this guy's story. Um Maybe before we talk about America, one small question about India for the other foreigner founders, you know, founders from other countries who want to expand in this country. What's your advice to them? I think you just do it. Uh just uh book a flight ticket and come there a few weeks, discuss with people, meet people and in general are very entrepreneurial mindset. So you will find good relationship that you can start using and developing. Just a matter of what I did is that just go to India once you, once you are there, things naturally develop and this whole angle about the population being really big, it's a very legitimate reason to be here, right? Like because the market size is that big and it's growing, it's 8% growth of the GDP per year. It's bigger as in a population that's becoming richer, a big population that's becoming richer. That's the business logic about being here, right? Because at the end of the day, business has to be a little ruthless and mat mathematical. For me, the the initial reason I went to India is but um I was growing very fast in Belgium. Um I was a small company like 20 employees when I went to India and when you grow fast, I was signing project that was um the revenue of the project was bigger than my turnover. The presenting year. So bigger project more than my turnover. But once you do that, you quickly need to recruit and set up the team to deliver the client. And the problem I faced in Belgium. Um If I needed, I had 20 reports. If I needed 20 more, it was like 6 to 9 months to get them, but I just signed a client so I needed it right away. So it's not, it's not so much about the cost of the developers. It was that I needed to uh grow faster. And um and so I had this before because at the end, I wanted to recruit in Belgium. So I recruited Indians so that I have more time to catch up with my, they were sitting in India. Yes. How did you come to know that India has this developer access? Oh Everyone knows that everyone in the tech world knows that. If it was a center of the world, everyone knows that. Like you've heard of invoices and T CS, of course. But have you heard of them before you came to India? And how do you look at invoices and TC si never work with them. So I don't know. But what have you heard it? I mean T CS is 400,000 people. Can you imagine? 400 thousands? It's, it's huge. I saw you reading a book about the Tata group. Yeah, I just thought it page 20 or something. Why are you reading that? I read a lot of books but specifically the Tata Group book you're reading because you're in India. Uh, yes. But I think I would have read it before. No, I just, because it's one of the book I'm reading now. Ok. Coming back to America. Uh, three years in Silicon Valley. You live there? Yes. Uh Tell me everything, man. Like, what was your life like? What were the conversations like? Did you actually get a view of the future? Did you have conversations about A I back then? Which year is this one was seven or eight\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"that. You like how you're working, right? The reason is that um uh public companies tend to refocus on the short term, you know, you have to uh publish earning codes with the, the sales number and if the numbers are good, everyone is happy, they buy the shares. If numbers are bad, people are not happy and your employees are frustrated because they have shares and it's bad. So public companies have a tendency to focus on the short term to saves, saves of the moments of the quarter and so on. I don't want that the success of FU is always to build for the long term. And I don't want to see on to look for the short term or the sales number of the quarter. One, the other thing is I'm so much focused on productivity and efficiency. Uh When you get public, you need extra layers of reporting transparency, uh anything like that. Uh So second reason I don't want that I want to be super efficient, decide right away instead of asking the board of directors. Um And third, I like open and transparent communication. You know, I just said the company was 4.5 billion of euro. If I was a public company, I could go to jail because I disclosed information uh not be before the earning calls. I think if, if I would have sent that to maybe not publicly but to some I could go to jail. I don't want that. I want to be able to say whatever I want to inform my employees uh and be transparent. Why do you think founders choose to go public? I think a lot of them don't understand, it's just a way to get cash. Um But to understand the consequence of that, most of them don't catch it really another thing. It's bad. I think as a source of cash public is quite good, it's efficient but it comes with some drawbacks like you have to uh have extra layers of reporting complexity. You cannot disclose information and it will refocus the mindset to the short term for some companies. It's good. Some companies need to focus on the short term but it's not us. You know, I would go as far as saying and I might be totally wrong while saying this, but I think there's a bit of a glamour factor also. Yeah, it's a way of being recognized but it's very short term. Like the moment you get public, everyone praise you, you get a lot of praise and then it goes back to reality after deal with the devil. Yeah, you get the same articles that we publish the de because it not big deal. But, um, I'm extreme in everything I do for me. If I lose 1% of productivity, it's bad. I wouldn't want that for do. Um, but, but it's not the devil. It's a, what's the best career advice you ever got in your life from someone? Just do it. That's true because a lot of people a re thinking waiting for the good idea. Um, deciding how we should do it sometime it's just about move on, get the job done first, get the job and maybe it works. Maybe it won't work. But at least you move forward and what's the worst advice you have about advice? I don't know. Um, open uh uh, no, I didn't get bad advice. I didn't follow advice. I don't have mentors and everything. I was working in the other office, which is a farm, in a farm, quite alone, not meeting a lot of people. So I didn't get a lot of feedback. I'm gonna give you a compliment again. Same compliment. You're a crazy guy. Like I have not met anyone like you on the show. No, I think a lot of people who bootstrap do that. You start from where you are and your small things and I don't just mean your professional and even the guy you are, it's very different man. Like, you know, I, I have not seen this on the show and I've spoken to like 600 people, like I've not met someone who's done so much materially, but it's still so humble. Like I still feel you're like a code on the inside. You know, you, that's what I love. I am. A but then that affects a lot of how you look at life. Like someone, not someone else. Many other people in your position would have accomplished what you've accomplished at this point. Either would have chosen to sell it off and just relax or, you know, live more. But then will they be happy by doing that? I think different people have different life stories for me. There is nothing better that I can do than to do. The best I can do is to continue improving the software for companies. It's, I feel like I don't see what I can do better than that, I mean, are you changing as a person as you age? Not as a professional as a human being. Are you changing? I become better. No, I think, no, I become slower because of the age. Um But I think the vision and uh what I wanted to do has always been the same uh not at the very beginning but after a few years it, it has been there. How do you look at Silicon Valley and San Francisco generally? Is it, is it always going to be the center of tech in the world or? Yes, they have a big advance. Um For not for the reason we think the main reason is the cash. They have so many V CS or old ex Google employs with plenty of millions to invest that basically any ID can, can live there and when, when all the ID can leave, some of them will be good and will make a good company. Do you visit? I have an office in San Francisco. Yes. And before office was in uh uh in Silicon Valley and I lived three years there. You lived three years with the family? Yes. Can you talk to me more right now? You're OK to talk to me. Are you getting bored? No, you're enjoying this. I just want to stretch the conversation more. I want to get to know more. Let's go. You don't mind me asking all these questions, right? Like all this time How are you feeling, by the way, in this? Iiiii, I enjoy the, the, the, it's good. We have a good conversation and it's fun because you're getting to think. Uh, yes. And for me it's a different thing that what I used to do. So it's good. Ok. Um, usually people like yourself who come on the show, it's a thought exercise for them because the questions go, like, pretty intense. So, especially entrepreneurs enjoyed being on the show because they get to think much more. They get to reflect. I don't know if you're in that zone. I don't need to think that much because I know my subject. So these things I'm used to talk about. So what value is this conversation adding to you? Not, not, not just you, I'm surprised that you find that the discussion is so good for you that you get a lot of value from it for me just no matter. Ok, but you are adding a lot of value. Like that's why I'm surprised. And it's good to hear. I'm sure this one is going to get international viewers as well because you've not just spoken to the Indian audiences. You know, you've spoken to like, like a lot of people want to expand the businesses in India and they don't know how to my solution to all of them. And I've been asked this question abroad is I think you need to tie up with an Indian partner. Like Indians have the team mentality also like as we value to find. Uh So, I mean, that was my advice until today's podcast. Now, I'll just send them this podcast. Look at this guy's story. Um Maybe before we talk about America, one small question about India for the other foreigner founders, you know, founders from other countries who want to expand in this country. What's your advice to them? I think you just do it. Uh just uh book a flight ticket and come there a few weeks, discuss with people, meet people and in general are very entrepreneurial mindset. So you will find good relationship that you can start using and developing. Just a matter of what I did is that just go to India once you, once you are there, things naturally develop and this whole angle about the population being really big, it's a very legitimate reason to be here, right? Like because the market size is that big and it's growing, it's 8% growth of the GDP per year. It's bigger as in a population that's becoming richer, a big population that's becoming richer. That's the business logic about being here, right? Because at the end of the day, business has to be a little ruthless and mat mathematical. For me, the the initial reason I went to India is but um I was growing very fast in Belgium. Um I was a small company like 20 employees when I went to India and when you grow fast, I was signing project that was um the revenue of the project was bigger than my turnover. The presenting year. So bigger project more than my turnover. But once you do that, you quickly need to recruit and set up the team to deliver the client. And the problem I faced in Belgium. Um If I needed, I had 20 reports. If I needed 20 more, it was like 6 to 9 months to get them, but I just signed a client so I needed it right away. So it's not, it's not so much about the cost of the developers. It was that I needed to uh grow faster. And um and so I had this before because at the end, I wanted to recruit in Belgium. So I recruited Indians so that I have more time to catch up with my, they were sitting in India. Yes. How did you come to know that India has this developer access? Oh Everyone knows that everyone in the tech world knows that. If it was a center of the world, everyone knows that. Like you've heard of invoices and T CS, of course. But have you heard of them before you came to India? And how do you look at invoices and TC si never work with them. So I don't know. But what have you heard it? I mean T CS is 400,000 people. Can you imagine? 400 thousands? It's, it's huge. I saw you reading a book about the Tata group. Yeah, I just thought it page 20 or something. Why are you reading that? I read a lot of books but specifically the Tata Group book you're reading because you're in India. Uh, yes. But I think I would have read it before. No, I just, because it's one of the book I'm reading now. Ok. Coming back to America. Uh, three years in Silicon Valley. You live there? Yes. Uh Tell me everything, man. Like, what was your life like? What were the conversations like? Did you actually get a view of the future? Did you have conversations about A I back then? Which year is this one was seven or eight\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"we can do the pivot in the business model and say, OK, no, let's refocus on making a clean product. And that's when the, the adventure of Voodoo started. The mindset has always been the same is to develop business apps to help companies be more efficient, more productive. From a first time entrepreneur's perspective, what I'd like to say is that a first time entrepreneur has a lot of random business challenges that you don't anticipate in like accounting like uh HR management and the list goes on. So I your software handles all those miscellaneous business problems as well. So, so uh the, the what is it do today? Uh It's a suite of business apps. We have applications for pretty much everything SME S needs. Like you need an accounting software. We have one AC RM. We have one, we want to create a website. We have a website builder. You need a inventory management software with barcodes can be picked and you receive deliver. We have one app and if you put all these apps together, you have fully integrated company. And um and that's what we do. We offer tools to small and mid size companies so that they, they can perform better. What I find crazy about this is that you have a lot of data with you also. So you will be able to understand how different countries go about business in different ways. Yes. Yes, we have uh 12 millions of users. So it's probably the most installed management software out there. Er, p at least. Um so, and we are active in, we do accounting for 150 countries. So we are one of the largest uh spread uh in terms of different countries. You're a brave guy. Uh I'm just a good worker. I think you're just a hard working guy. I'm a hard working for the first seven years. I didn't get a single day or holiday for seven years and I was working like 14 days, 14 hours a day. It's not anymore the case. No, Saturday and Sunday. I, I work less but uh getting older, you think that plays a role? I think I don't have the same level of energy. I feel that already. Between 22 and 30. How old are you? I'm 30 your time. But I feel a difference in the energy I felt when I was 22. I work for 40. I'm 44. Really? How do you look so young dude? Um I don't know. It's good to know. Good genetics. Yes. You're a happy guy on the inside. I'm super happy. I love my job. I love my company. I love my project. I'm really happy in life. What are you the happiest about from a business perspective about your whole business career? Um So what I do like is that what we do as is super important uh because it helps companies, uh it helps people, we don't do management software for managers or for managing companies. I'm not interested in that. It's not interesting. I do tools so that every employee in the companies can do their job better, can save time, do less administrative tasks, less boring task. So we really help millions of people having a better life because if you think about it, you probably spend 30 40% of your time at work. So better do it with good tools so that you enjoy doing rather than doing boring administrative rerecording of data. And I feel like we have a massive impact on uh on the society because of that. We do it with a, we didn't talk about it but with a special business model, which is open source. So a lot of people can get it for free download, modify. And so we are reaching countries that could not afford that kind of software because it's free. Uh So the impact is really big of what we do. Can you explain what open source means? One and two? Why did you make it open source? Because it's a very different mentality. Like if you have built out a product, if you've built out a software, uh there has to be an intention in turning it into an open source software, open sources, you have kept the software available for the public. Yes. So open source is a license that says instead of constraining the software and say when you buy my software, you have minimum 10 user, maximum 10 user, you have this, this, this, this instead of putting constraints, we put rules so that we guarantee the user that they will be able to use the software for free. Um get the source code of the software so they can learn it, modify it for free and all the things will be free forever. So it's like a protection for the user. And the reason I did open source is because I'm passionate about open source since I was a student, I only use myself open source software. So when I developed software, I did it open source because you get a template from which you can build upon. No, because II I did, I didn't want to do another model. It was something I was, I'm passionate about that. I'd like to, I think software is knowledge and knowledge should be shared and I think short software, it's like knowledge should be shared to the world. Um And I think it's better, it was very hard because when you do a software for free getting money out of that is really difficult. So it took me uh maybe 15 years to understand the business model. What is the business model um Nowadays. So I tried everything I started as a service company as I explained to you. Then I moved to maintenance, selling service, like support upgrade. Um didn't work that well, it worked. But uh after 500 employees, I couldn't, I was, I had, I've had like seven years close to bank bankruptcy. So at some point it's ok. I have to change. My passion about open source is good, but at some point, it's good to remain alive too. Um And so now the business model that works is what we called open core and an open core business. But anyways where you have 80% of the applications, a re free and open source and we add 20% of application where you have to pay for premium. It's like a premium, but it's like two different products. Some people can just use the open source one and others uh can use the what we call a do enterprise, which is the full version. That's the one that is working for you right now. Yes, for EXA MP. If you need AC RM, it's open source is free. You need a website, free an open source. You need inventory sales, purchase, it's free and open source. You need accounting. You will have to pay the accounting version because it's only in the paid version. So people gain trust in your software from the free part. And then they say, yeah, this is a good software design is great. Functionality is great. Let me pay for like this additional. Uh Yes, some do that. 10% 90% doesn't pay, never pay. But the best is the word of mouth. You know, when you build a company, the most difficult part is marketing, word of mouth, building a big audience of users. And, and the good thing when you are free is that you quickly get billions of users. And uh even though they will never pay some of them, what they will do is bring you uh more customer because they will tell to their friend this uh software is great. I'm using every day. You should check it and maybe one of them will pay. So based on those 10% parts of your software that are actually premium which people pay for. You're supporting the whole business, including the 90% which is for me, it was a very philosophical problem because I was passionate about about source and I did not want to sell proper source of software. I was against that. Uh But it was a very bad decision. It was a very bright mindset because at the time I had something like maybe 100 developers maximum, I couldn't pay more. Um And now that I have 10% non open source or 20% non open source, 80% open source, I can afford paying hundreds of developers. Uh So I contribute way more to the open source world than what I did before, even though I'm not 100% open source today. So it's something I didn't understand, took me years because I refused that. But once I did that, I switched the business model and then the company started to skyrocket. You know, there's a lot of lessons that Indian entrepreneurs, young Indian entrepreneurs can actually learn from this in terms of your selling to the world. Here, we, a lot of us have dreams about selling to the world as well, but I don't think they are educated in that aspect in terms of if you built out something in India, how do you ensure that someone sitting in Britain or Nigeria or Brazil would actually use your stuff? So you, you've had an expansion outside your own country, right? Yes. You know, we are Belgians, Belgium is nothing. It's tell me and the people. So by nature, if you want to do business, we a re forced to export because our market is nothing. Um You don't have the SA me issue in India, but you have also a lot strong incentive to export uh in software. It's easy, it's just build the best software. The reason all the works is we have the best uh you have, we have the best CRM. We have a modern website builder. We much better than wordpress or, or, or, or Shopify uh and we build the best, took us 20 years. But once you get the best software is like compound interest you build and you build and you build everywhere, it gets better and better and better. And the revenue you get from the software increase exponentially based on what you build. It's like uh creating a massive asset that is joining more and more revenue over the years. But it takes time, it takes a lot of time because in order to be the best, uh you have, you have to develop and develop and develop, especially in open source, in open source, it's very hard because, you know, in property software, when you sell the software on a license, you can have a lot of competitors and then they will all differentiate themselves. Open source is like a transparent market. Um It's like because it's free, everyone will test before buying so they test, they play with it and so everyone will choose the best product. So in the open source, it's a winner. Take all market, there is one winner but no second player and that is very hard. So it requires for you to invest a lot in research and development um in order to build the best product. And before you, you are not the best, you, you get\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"Can you detail the speaker's journey from starting as a coder to becoming a successful entrepreneur, including the pivot in their business model?\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup the new chain using Pinecone as the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": db.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"What are the main challenges and advantages of doing business in India, including insights on market sensitivity, price, and speed of decision-making?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, some key challenges and advantages of doing business in India that were discussed include:\n",
      "\n",
      "Challenges:\n",
      "\n",
      "- India is a very price sensitive market. Customers focus heavily on getting the lowest price rather than prioritizing quality or service.\n",
      "\n",
      "- Indian customers often want to do things themselves rather than buying services, in order to save money. This makes it hard to sell additional services.\n",
      "\n",
      "- Marketing can be difficult as businesses need to build awareness from scratch when entering the Indian market. \n",
      "\n",
      "Advantages:\n",
      "\n",
      "- India is very open to international businesses compared to some other markets like China. Many people speak English and the business environment is friendly.\n",
      "\n",
      "- Decision making can be faster than other markets like Europe or Africa where sales cycles are longer. Indians want to move quickly.\n",
      "\n",
      "- There is a big need for growth and modernization that international companies can fill, providing huge opportunities.\n",
      "\n",
      "- The large population means there is a lot of affordable labor, enabling cost savings.\n",
      "\n",
      "In summary, the price sensitivity and frugal mindset of Indian customers poses challenges, but the openness to foreign businesses, faster decision making, and growth opportunities make India an attractive market overall. Being affordable and adapting to the local culture are keys to success.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
